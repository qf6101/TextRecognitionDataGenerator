{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 10232\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import uuid\n",
    "import shutil\n",
    "import os\n",
    "from functools import partial\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = '/datadisk2/qfeng/TextRecognitionDataGenerator'\n",
    "data_path = Path('/datadisk4/tyin/gpt2/wiki_zh')\n",
    "outp_path = Path('/datadisk2/qfeng/ocr_synthesis/text_detection_data_simsun/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datadisk2/qfeng/TextRecognitionDataGenerator\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/datadisk2/qfeng/TextRecognitionDataGenerator'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd $project_path\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trdg.generators import CompoundGenerator\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = namedtuple('Conf', ['width', 'background_type', 'fit', 'line_margin', 'skewing_angle', 'random_skew', 'box_skewing_angle', 'box_random_skew', 'size'])\n",
    "conf.size = 96\n",
    "conf.background_type = 1\n",
    "conf.fit = True\n",
    "conf.line_margin = 5\n",
    "conf.skewing_angle = 0\n",
    "conf.random_skew = True\n",
    "conf.box_skewing_angle = 3\n",
    "conf.box_random_skew = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = CompoundGenerator(background_type=conf.background_type, fit=conf.fit, line_margin=conf.line_margin, skewing_angle=conf.skewing_angle, random_skew=conf.random_skew, box_skewing_angle= conf.box_skewing_angle, box_random_skew=conf.box_random_skew, size=conf.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_letters_pattern = re.compile(r'[a-zA-Z]{3,}')\n",
    "unchinese_pattern = re.compile(r'[^\\u4e00-\\u9fa5\\s\\w]')\n",
    "html_pattern = re.compile(\n",
    "    r'(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'\n",
    ")\n",
    "other_url_pattern = re.compile(r'\\/\\/.*|[A-Za-z]:\\\\.*|[A-Za-z]:\\/.*')\n",
    "\n",
    "def find_chinese(inp):\n",
    "    outp = re.sub(long_letters_pattern, '', inp)\n",
    "    outp = re.sub(unchinese_pattern, '', outp)\n",
    "    return outp\n",
    "\n",
    "\n",
    "def cut_html_tags(inp):\n",
    "    return re.sub(html_pattern, '', inp)\n",
    "\n",
    "\n",
    "def cut_other_url_tags(inp):\n",
    "    return re.sub(other_url_pattern, '', inp)\n",
    "\n",
    "\n",
    "def cut_url_tags(inp):\n",
    "    outp = cut_html_tags(inp)\n",
    "    outp = cut_other_url_tags(outp)\n",
    "    return outp\n",
    "\n",
    "def cut_text(inp):\n",
    "    return find_chinese(cut_url_tags(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_symbol = ['&', '：', '[', ']', '、', '（', '）', ':']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_texts(inp):\n",
    "    outp = []\n",
    "    buf = []\n",
    "    for i in inp:\n",
    "        buf.append(i)\n",
    "        \n",
    "        if random.randint(0, 5) == 0:\n",
    "            buf.append(special_symbol[random.randint(0, len(special_symbol)-1)])\n",
    "        \n",
    "        if random.randint(0, 10) == 0:\n",
    "            outp.append(''.join(buf[:16]))\n",
    "            buf = []\n",
    "            \n",
    "    return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    for d in data_path.glob('*/*'):\n",
    "        with open(str(d), 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                data = json.loads(line.strip('\\n'))\n",
    "                for t in data['text'].split('\\n'):\n",
    "                    t = cut_text(t)\n",
    "                    if len(t.strip(' ')) > 0:\n",
    "                        texts.extend(make_texts(t))                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data()\n",
    "# len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datadisk2/qfeng/ocr_synthesis/text_detection_data_simsun/input_texts.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-9f3f2d21ebf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp_path\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'input_texts.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datadisk2/qfeng/ocr_synthesis/text_detection_data_simsun/input_texts.txt'"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "\n",
    "with open(str(outp_path/'input_texts.txt')) as f:\n",
    "    for line in f.readlines():\n",
    "        texts.append(line.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = 'SimSun'\n",
    "\n",
    "def gen_image(inp_texts):    \n",
    "    args = namedtuple('Args', ['font', 'texts', 'bold', 'box_margins', 'box_lines', 'alignment'])\n",
    "    n_texts = random.randint(1, 5)\n",
    "    args.texts = [inp_texts[random.randint(0, len(inp_texts))] for _ in range(n_texts)]   \n",
    "    args.font = '/datadisk2/qfeng/TextRecognitionDataGenerator/trdg/fonts/cn/SimSun.ttf'\n",
    "    args.bold = False\n",
    "    args.box_margins = (random.randint(16, 256), random.randint(16, 256))\n",
    "    args.box_lines = (random.randint(0, 1), random.randint(0, 1), random.randint(0, 1), random.randint(0, 1))\n",
    "    args.alignment = random.randint(0, 1)\n",
    "    img, img_locs = generator.gen(args)\n",
    "    return img, img_locs, args.texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, img_locs, c = gen_image(texts)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 10233\n"
     ]
    }
   ],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated(tag, inp_texts, size, font):\n",
    "    gt_dname = outp_path/(tag + '_gt')\n",
    "    img_dname = outp_path/(tag + '_img')\n",
    "   \n",
    "    if gt_dname.exists():\n",
    "        shutil.rmtree(str(gt_dname))\n",
    "    gt_dname.mkdir()\n",
    "        \n",
    "    if img_dname.exists():\n",
    "        shutil.rmtree(str(img_dname))\n",
    "    img_dname.mkdir()\n",
    "    \n",
    "    for _ in range(size):\n",
    "        img, img_locs, contents = gen_image(inp_texts)\n",
    "        name = str(uuid.uuid4())\n",
    "        img.save(str((img_dname/(name + '.png'))))\n",
    "        \n",
    "        with open(str(gt_dname/(name + '.txt')), 'w') as f:            \n",
    "            for c, loc in zip(contents, img_locs):\n",
    "                line = []\n",
    "                for i_ in loc:\n",
    "                    line.append(str(round(i_[0], 2)))\n",
    "                    line.append(str(round(i_[1], 2)))\n",
    "                line.append('\"' + c + '\"')\n",
    "                line.append(font)\n",
    "                f.write(','.join(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_save(tag, inp, n_splits, bs, font, n_workers):\n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as ex:\n",
    "        func = partial(save_generated, size=bs, font=font)\n",
    "        step = len(inp)//n_splits\n",
    "        splits = list(range(0, len(inp), step))\n",
    "        for i in range(1, len(splits)):\n",
    "            print(splits[i-1], splits[i])\n",
    "            ex.submit(func, tag + '_' + str(i), inp[splits[i-1]:splits[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 280948\n",
      "280948 561896\n",
      "561896 842844\n",
      "842844 1123792\n",
      "1123792 1404740\n",
      "1404740 1685688\n",
      "1685688 1966636\n",
      "1966636 2247584\n",
      "2247584 2528532\n",
      "2528532 2809480\n",
      "2809480 3090428\n",
      "3090428 3371376\n",
      "3371376 3652324\n",
      "3652324 3933272\n",
      "3933272 4214220\n",
      "4214220 4495168\n",
      "4495168 4776116\n",
      "4776116 5057064\n",
      "5057064 5338012\n",
      "5338012 5618960\n",
      "5618960 5899908\n",
      "5899908 6180856\n",
      "6180856 6461804\n",
      "6461804 6742752\n",
      "6742752 7023700\n",
      "7023700 7304648\n",
      "7304648 7585596\n",
      "7585596 7866544\n",
      "7866544 8147492\n",
      "8147492 8428440\n",
      "8428440 8709388\n",
      "8709388 8990336\n",
      "8990336 9271284\n",
      "9271284 9552232\n",
      "9552232 9833180\n",
      "9833180 10114128\n",
      "10114128 10395076\n",
      "10395076 10676024\n",
      "10676024 10956972\n",
      "10956972 11237920\n",
      "11237920 11518868\n",
      "11518868 11799816\n",
      "11799816 12080764\n",
      "12080764 12361712\n",
      "12361712 12642660\n",
      "12642660 12923608\n",
      "12923608 13204556\n",
      "13204556 13485504\n",
      "13485504 13766452\n",
      "13766452 14047400\n",
      "14047400 14328348\n",
      "14328348 14609296\n",
      "14609296 14890244\n",
      "14890244 15171192\n",
      "15171192 15452140\n",
      "15452140 15733088\n",
      "15733088 16014036\n",
      "16014036 16294984\n",
      "16294984 16575932\n",
      "16575932 16856880\n",
      "16856880 17137828\n",
      "17137828 17418776\n",
      "17418776 17699724\n",
      "17699724 17980672\n",
      "17980672 18261620\n",
      "18261620 18542568\n",
      "18542568 18823516\n",
      "18823516 19104464\n",
      "19104464 19385412\n",
      "19385412 19666360\n",
      "19666360 19947308\n",
      "19947308 20228256\n",
      "20228256 20509204\n",
      "20509204 20790152\n",
      "20790152 21071100\n",
      "21071100 21352048\n",
      "21352048 21632996\n",
      "21632996 21913944\n",
      "21913944 22194892\n",
      "22194892 22475840\n",
      "22475840 22756788\n",
      "22756788 23037736\n",
      "23037736 23318684\n",
      "23318684 23599632\n",
      "23599632 23880580\n",
      "23880580 24161528\n",
      "24161528 24442476\n",
      "24442476 24723424\n",
      "24723424 25004372\n",
      "25004372 25285320\n",
      "25285320 25566268\n",
      "25566268 25847216\n",
      "25847216 26128164\n",
      "26128164 26409112\n",
      "26409112 26690060\n",
      "26690060 26971008\n",
      "26971008 27251956\n",
      "27251956 27532904\n",
      "27532904 27813852\n",
      "27813852 28094800\n"
     ]
    }
   ],
   "source": [
    "parallel_save(tag='texts', inp=texts, n_splits=100, bs=50000, font=font, n_workers=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/datadisk2/qfeng/ocr_synthesis/input_texts.txt', 'w') as f:\n",
    "#     for t in texts:\n",
    "#         f.write(t + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_texts = []\n",
    "\n",
    "for _ in range(100000):\n",
    "    buf = []\n",
    "    n_digits = random.randint(5, 16)\n",
    "    \n",
    "    for _ in range(n_digits):\n",
    "        buf.append(str(random.randint(0, 9)))\n",
    "        digit_texts.append(''.join(buf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 26261\n",
      "26261 52522\n",
      "52522 78783\n",
      "78783 105044\n",
      "105044 131305\n",
      "131305 157566\n",
      "157566 183827\n",
      "183827 210088\n",
      "210088 236349\n",
      "236349 262610\n",
      "262610 288871\n",
      "288871 315132\n",
      "315132 341393\n",
      "341393 367654\n",
      "367654 393915\n",
      "393915 420176\n",
      "420176 446437\n",
      "446437 472698\n",
      "472698 498959\n",
      "498959 525220\n",
      "525220 551481\n",
      "551481 577742\n",
      "577742 604003\n",
      "604003 630264\n",
      "630264 656525\n",
      "656525 682786\n",
      "682786 709047\n",
      "709047 735308\n",
      "735308 761569\n",
      "761569 787830\n",
      "787830 814091\n",
      "814091 840352\n",
      "840352 866613\n",
      "866613 892874\n",
      "892874 919135\n",
      "919135 945396\n",
      "945396 971657\n",
      "971657 997918\n",
      "997918 1024179\n",
      "1024179 1050440\n"
     ]
    }
   ],
   "source": [
    "parallel_save(tag='digit', inp=digit_texts, n_splits=40, bs=5000, font=font, n_workers=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_letter_texts = []\n",
    "\n",
    "for _ in range(100000):\n",
    "    buf = []\n",
    "    n_digits = random.randint(5, 16)\n",
    "    \n",
    "    for _ in range(n_digits):\n",
    "        buf.append(chr(random.randint(65, 90)))\n",
    "        small_letter_texts.append(''.join(buf))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 26303\n",
      "26303 52606\n",
      "52606 78909\n",
      "78909 105212\n",
      "105212 131515\n",
      "131515 157818\n",
      "157818 184121\n",
      "184121 210424\n",
      "210424 236727\n",
      "236727 263030\n",
      "263030 289333\n",
      "289333 315636\n",
      "315636 341939\n",
      "341939 368242\n",
      "368242 394545\n",
      "394545 420848\n",
      "420848 447151\n",
      "447151 473454\n",
      "473454 499757\n",
      "499757 526060\n",
      "526060 552363\n",
      "552363 578666\n",
      "578666 604969\n",
      "604969 631272\n",
      "631272 657575\n",
      "657575 683878\n",
      "683878 710181\n",
      "710181 736484\n",
      "736484 762787\n",
      "762787 789090\n",
      "789090 815393\n",
      "815393 841696\n",
      "841696 867999\n",
      "867999 894302\n",
      "894302 920605\n",
      "920605 946908\n",
      "946908 973211\n",
      "973211 999514\n",
      "999514 1025817\n",
      "1025817 1052120\n"
     ]
    }
   ],
   "source": [
    "parallel_save(tag='small_letter', inp=small_letter_texts, n_splits=40, bs=5000, font=font, n_workers=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_letter_texts = []\n",
    "\n",
    "for _ in range(100000):\n",
    "    buf = []\n",
    "    n_digits = random.randint(5, 16)\n",
    "    \n",
    "    for _ in range(n_digits):\n",
    "        buf.append(chr(random.randint(97, 122)))\n",
    "        big_letter_texts.append(''.join(buf))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 26234\n",
      "26234 52468\n",
      "52468 78702\n",
      "78702 104936\n",
      "104936 131170\n",
      "131170 157404\n",
      "157404 183638\n",
      "183638 209872\n",
      "209872 236106\n",
      "236106 262340\n",
      "262340 288574\n",
      "288574 314808\n",
      "314808 341042\n",
      "341042 367276\n",
      "367276 393510\n",
      "393510 419744\n",
      "419744 445978\n",
      "445978 472212\n",
      "472212 498446\n",
      "498446 524680\n",
      "524680 550914\n",
      "550914 577148\n",
      "577148 603382\n",
      "603382 629616\n",
      "629616 655850\n",
      "655850 682084\n",
      "682084 708318\n",
      "708318 734552\n",
      "734552 760786\n",
      "760786 787020\n",
      "787020 813254\n",
      "813254 839488\n",
      "839488 865722\n",
      "865722 891956\n",
      "891956 918190\n",
      "918190 944424\n",
      "944424 970658\n",
      "970658 996892\n",
      "996892 1023126\n",
      "1023126 1049360\n"
     ]
    }
   ],
   "source": [
    "parallel_save(tag='big_letter', inp=big_letter_texts, n_splits=40, bs=5000, font=font, n_workers=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_texts = []\n",
    "\n",
    "for _ in range(100000):\n",
    "    buf = []\n",
    "    n_digits = random.randint(5, 16)\n",
    "    \n",
    "    for _ in range(n_digits):\n",
    "        if random.randint(0, 10) == 0:\n",
    "            buf.append('-')\n",
    "        elif random.randint(0,1) == 0:        \n",
    "            buf.append(chr(random.randint(65, 90)))\n",
    "        else:\n",
    "            buf.append(chr(random.randint(97, 122)))\n",
    "        letter_texts.append(''.join(buf))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow)",
   "language": "python",
   "name": "conda_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
